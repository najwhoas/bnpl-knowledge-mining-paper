{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "collapsed_sections": [
        "TnfArzrsn_3n",
        "f0cyviMho1Fl",
        "6krFZkAhpBQa",
        "-IZLUiovaUg-"
      ],
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 10419368,
          "sourceType": "datasetVersion",
          "datasetId": 6424561
        }
      ],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Import Library**"
      ],
      "metadata": {
        "id": "wq0xhCO6FR01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk nlp-id gdown textblob opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2b2Y68iFKWl",
        "outputId": "3f3df71d-edea-48ac-de56-ddce17ad98bd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:18.670646Z",
          "iopub.execute_input": "2025-01-10T09:33:18.670935Z",
          "iopub.status.idle": "2025-01-10T09:33:30.523706Z",
          "shell.execute_reply.started": "2025-01-10T09:33:18.670913Z",
          "shell.execute_reply": "2025-01-10T09:33:30.522643Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nCollecting nlp-id\n  Downloading nlp_id-0.1.18.0-py3-none-any.whl.metadata (7.7 kB)\nRequirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\nRequirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\nCollecting opendatasets\n  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.16.0)\nCollecting huggingface-hub==0.23.4 (from nlp-id)\n  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\nCollecting nltk\n  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.10/dist-packages (from nlp-id) (1.26.4)\nCollecting scikit-learn==1.5.1 (from nlp-id)\n  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: scipy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from nlp-id) (1.13.1)\nCollecting wget==3.2 (from nlp-id)\n  Downloading wget-3.2.zip (10 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.23.4->nlp-id) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.23.4->nlp-id) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.23.4->nlp-id) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.23.4->nlp-id) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.23.4->nlp-id) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.23.4->nlp-id) (4.12.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.1->nlp-id) (3.5.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\nRequirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.17)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.8.30)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\nRequirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.2.3)\nRequirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\nDownloading nlp_id-0.1.18.0-py3-none-any.whl (8.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\nBuilding wheels for collected packages: wget\n  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=88c08073663b4816ed7a2ed9b184d99e2a00f79d8e18b2efa2f06c833d43b272\n  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\nSuccessfully built wget\nInstalling collected packages: wget, nltk, scikit-learn, huggingface-hub, opendatasets, nlp-id\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.24.7\n    Uninstalling huggingface-hub-0.24.7:\n      Successfully uninstalled huggingface-hub-0.24.7\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.23.4 nlp-id-0.1.18.0 nltk-3.9.1 opendatasets-0.1.22 scikit-learn-1.5.1 wget-3.2\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1cXaOtuw6xqWL6KDjZqvkzGYsiyyr0X1y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHLnN3S9nPQP",
        "outputId": "0553d39b-9611-4def-e07b-889d0fae9cfb",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:30.524999Z",
          "iopub.execute_input": "2025-01-10T09:33:30.525268Z",
          "iopub.status.idle": "2025-01-10T09:33:34.751742Z",
          "shell.execute_reply.started": "2025-01-10T09:33:30.525249Z",
          "shell.execute_reply": "2025-01-10T09:33:34.750720Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=1cXaOtuw6xqWL6KDjZqvkzGYsiyyr0X1y\nTo: /kaggle/working/slang.txt\n100%|██████████████████████████████████████| 32.8k/32.8k [00:00<00:00, 53.5MB/s]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import logging"
      ],
      "metadata": {
        "id": "hrpoKM9qeepO",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:34.758150Z",
          "iopub.execute_input": "2025-01-10T09:33:34.758453Z",
          "iopub.status.idle": "2025-01-10T09:33:35.751957Z",
          "shell.execute_reply.started": "2025-01-10T09:33:34.758425Z",
          "shell.execute_reply": "2025-01-10T09:33:35.751253Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from textblob import TextBlob\n",
        "from nltk.corpus import stopwords\n",
        "from nlp_id.lemmatizer import Lemmatizer\n",
        "from nlp_id.stopword import StopWord\n",
        "from nltk import word_tokenize\n",
        "from nlp_id.postag import PosTag\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('indonesian'))\n",
        "stopword = StopWord()\n",
        "lemmatizer = Lemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYGpT5uetnV_",
        "outputId": "acca3de6-9586-4768-c53d-02f991ea6616",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:35.752784Z",
          "iopub.execute_input": "2025-01-10T09:33:35.753096Z",
          "iopub.status.idle": "2025-01-10T09:33:37.267687Z",
          "shell.execute_reply.started": "2025-01-10T09:33:35.753073Z",
          "shell.execute_reply": "2025-01-10T09:33:37.266849Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Data Retrieval**"
      ],
      "metadata": {
        "id": "tmedqXoBFVb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "banking = pd.concat([pd.read_csv('/kaggle/input/bnpl-dataset-2024/en - banking.csv'), pd.read_csv('/kaggle/input/bnpl-dataset-2024/id - banking.csv')], ignore_index=True)\n",
        "ewallet = pd.concat([pd.read_csv('/kaggle/input/bnpl-dataset-2024/en - ewallet.csv'), pd.read_csv('/kaggle/input/bnpl-dataset-2024/id - ewallet.csv')], ignore_index=True)\n",
        "ecomm = pd.concat([pd.read_csv('/kaggle/input/bnpl-dataset-2024/en - ecomm.csv'), pd.read_csv('/kaggle/input/bnpl-dataset-2024/id - ecomm.csv')], ignore_index=True)\n",
        "lend = pd.concat([pd.read_csv('/kaggle/input/bnpl-dataset-2024/en - loan.csv'), pd.read_csv('/kaggle/input/bnpl-dataset-2024/id - loan.csv')], ignore_index=True)"
      ],
      "metadata": {
        "id": "wE7A_5WvFb9N",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:37.307895Z",
          "iopub.execute_input": "2025-01-10T09:33:37.308130Z",
          "iopub.status.idle": "2025-01-10T09:33:37.456855Z",
          "shell.execute_reply.started": "2025-01-10T09:33:37.308112Z",
          "shell.execute_reply": "2025-01-10T09:33:37.456194Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "banking['platform_type'] = 'banking'\n",
        "ewallet['platform_type'] = 'ewallet'\n",
        "ecomm['platform_type'] = 'ecomm'\n",
        "lend['platform_type'] = 'lend'"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:37.457591Z",
          "iopub.execute_input": "2025-01-10T09:33:37.457792Z",
          "iopub.status.idle": "2025-01-10T09:33:37.465759Z",
          "shell.execute_reply.started": "2025-01-10T09:33:37.457775Z",
          "shell.execute_reply": "2025-01-10T09:33:37.464974Z"
        },
        "id": "XeWqnEg6pvXs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "text = pd.concat([banking, ewallet, ecomm, lend], ignore_index=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:37.466553Z",
          "iopub.execute_input": "2025-01-10T09:33:37.466829Z",
          "iopub.status.idle": "2025-01-10T09:33:37.482801Z",
          "shell.execute_reply.started": "2025-01-10T09:33:37.466802Z",
          "shell.execute_reply": "2025-01-10T09:33:37.482118Z"
        },
        "id": "uBSvcEwapvXt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.drop(columns=['reviewId','userName','userImage','thumbsUpCount','reviewCreatedVersion','replyContent','repliedAt','appVersion'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:37.483559Z",
          "iopub.execute_input": "2025-01-10T09:33:37.483751Z",
          "iopub.status.idle": "2025-01-10T09:33:37.502870Z",
          "shell.execute_reply.started": "2025-01-10T09:33:37.483735Z",
          "shell.execute_reply": "2025-01-10T09:33:37.502186Z"
        },
        "id": "LayTwVuipvXt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "text.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OnO3YK02nAzQ",
        "outputId": "d8f60227-5f70-4138-bbf0-1145896108aa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:37.503529Z",
          "iopub.execute_input": "2025-01-10T09:33:37.503718Z",
          "iopub.status.idle": "2025-01-10T09:33:37.524969Z",
          "shell.execute_reply.started": "2025-01-10T09:33:37.503702Z",
          "shell.execute_reply": "2025-01-10T09:33:37.524298Z"
        }
      },
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                             content  score  \\\n0  banyak spam telepon untuk promosi ajakan buka ...      1   \n1  Aplikasi buruk, ketika saya ingin membayar Pay...      1   \n2  Bagi saya, aplikasi ini bekerja dengan sangat ...      5   \n3  Saya menerima SMS dari Bank Allo yang menyatak...      1   \n4  Indosat im3 terus mengirimi saya pesan tentang...      1   \n\n                    at platform_type  \n0   2024-12-11 4:15:16       banking  \n1   2024-10-09 3:25:54       banking  \n2  2024-03-31 18:46:17       banking  \n3   2022-12-23 9:14:44       banking  \n4  2023-06-15 10:05:25       banking  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>score</th>\n      <th>at</th>\n      <th>platform_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>banyak spam telepon untuk promosi ajakan buka ...</td>\n      <td>1</td>\n      <td>2024-12-11 4:15:16</td>\n      <td>banking</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Aplikasi buruk, ketika saya ingin membayar Pay...</td>\n      <td>1</td>\n      <td>2024-10-09 3:25:54</td>\n      <td>banking</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Bagi saya, aplikasi ini bekerja dengan sangat ...</td>\n      <td>5</td>\n      <td>2024-03-31 18:46:17</td>\n      <td>banking</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Saya menerima SMS dari Bank Allo yang menyatak...</td>\n      <td>1</td>\n      <td>2022-12-23 9:14:44</td>\n      <td>banking</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Indosat im3 terus mengirimi saya pesan tentang...</td>\n      <td>1</td>\n      <td>2023-06-15 10:05:25</td>\n      <td>banking</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "text.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:37.525718Z",
          "iopub.execute_input": "2025-01-10T09:33:37.525932Z",
          "iopub.status.idle": "2025-01-10T09:33:37.541009Z",
          "shell.execute_reply.started": "2025-01-10T09:33:37.525913Z",
          "shell.execute_reply": "2025-01-10T09:33:37.540214Z"
        },
        "id": "Ga5oVwbZpvXu",
        "outputId": "8a6eec1e-1a5e-44e0-ddc1-ce07aee226cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4784 entries, 0 to 4783\nData columns (total 4 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   content        4784 non-null   object\n 1   score          4784 non-null   int64 \n 2   at             4784 non-null   object\n 3   platform_type  4784 non-null   object\ndtypes: int64(1), object(3)\nmemory usage: 149.6+ KB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "text.isnull().sum()\n",
        "text.duplicated().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:37.541778Z",
          "iopub.execute_input": "2025-01-10T09:33:37.542024Z",
          "iopub.status.idle": "2025-01-10T09:33:37.555147Z",
          "shell.execute_reply.started": "2025-01-10T09:33:37.542006Z",
          "shell.execute_reply": "2025-01-10T09:33:37.554287Z"
        },
        "id": "7ZLd95GmpvXu",
        "outputId": "a7e1d117-8cba-4db7-bf49-3df1f30c6a00"
      },
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "text.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVmRa4UOpJ0C",
        "outputId": "789c35a4-d13f-4a87-f154-147d116ad627",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:37.556137Z",
          "iopub.execute_input": "2025-01-10T09:33:37.556344Z",
          "iopub.status.idle": "2025-01-10T09:33:37.569295Z",
          "shell.execute_reply.started": "2025-01-10T09:33:37.556319Z",
          "shell.execute_reply": "2025-01-10T09:33:37.568539Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4784 entries, 0 to 4783\nData columns (total 4 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   content        4784 non-null   object\n 1   score          4784 non-null   int64 \n 2   at             4784 non-null   object\n 3   platform_type  4784 non-null   object\ndtypes: int64(1), object(3)\nmemory usage: 149.6+ KB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Data Cleaning**"
      ],
      "metadata": {
        "id": "oJdd5EF4WfFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lowercase(review_text):\n",
        "  low = review_text.lower()\n",
        "  return low\n",
        "text['content'] = text['content'].apply(lambda low:lowercase(str(low)))"
      ],
      "metadata": {
        "id": "o_80gsDqYcjo",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:37.570122Z",
          "iopub.execute_input": "2025-01-10T09:33:37.570596Z",
          "iopub.status.idle": "2025-01-10T09:33:37.587817Z",
          "shell.execute_reply.started": "2025-01-10T09:33:37.570566Z",
          "shell.execute_reply": "2025-01-10T09:33:37.587169Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_hashtag(review_text, default_replace=\"\"):\n",
        "  hashtag = re.sub(r'#\\w+', default_replace, review_text)\n",
        "  return hashtag\n",
        "text['content'] = text['content'].apply(lambda hashtag: remove_hashtag(hashtag))"
      ],
      "metadata": {
        "id": "MzvuRB6SYwHa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:37.588494Z",
          "iopub.execute_input": "2025-01-10T09:33:37.588691Z",
          "iopub.status.idle": "2025-01-10T09:33:37.607037Z",
          "shell.execute_reply.started": "2025-01-10T09:33:37.588660Z",
          "shell.execute_reply": "2025-01-10T09:33:37.606209Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emoji(review_text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           u\"\\U0001f926-\\U0001f937\"\n",
        "                           u\"\\U00010000-\\U0010ffff\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', review_text)\n",
        "text['content'] = text['content'].apply(lambda emoji: remove_emoji(emoji))"
      ],
      "metadata": {
        "id": "LqV6biuiY8JE",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:37.607832Z",
          "iopub.execute_input": "2025-01-10T09:33:37.608111Z",
          "iopub.status.idle": "2025-01-10T09:33:37.660263Z",
          "shell.execute_reply.started": "2025-01-10T09:33:37.608084Z",
          "shell.execute_reply": "2025-01-10T09:33:37.659716Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_superscript(review_text):\n",
        "  number = re.compile(\"[\"u\"\\U00002070\"\n",
        "                      u\"\\U000000B9\"\n",
        "                      u\"\\U000000B2-\\U000000B3\"\n",
        "                      u\"\\U00002074-\\U00002079\"\n",
        "                      u\"\\U0000207A-\\U0000207E\"\n",
        "                      u\"U0000200D\"\n",
        "                      \"]+\", flags=re.UNICODE)\n",
        "  return number.sub(r'', review_text)\n",
        "text['content'] = text['content'].apply(lambda num: remove_superscript(num))"
      ],
      "metadata": {
        "id": "90AbqSB_ZBmW",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:37.660912Z",
          "iopub.execute_input": "2025-01-10T09:33:37.661108Z",
          "iopub.status.idle": "2025-01-10T09:33:37.689141Z",
          "shell.execute_reply.started": "2025-01-10T09:33:37.661092Z",
          "shell.execute_reply": "2025-01-10T09:33:37.688382Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(review_text, default_text=\" \"):\n",
        "  list_punct = string.punctuation\n",
        "  delete_punct = str.maketrans(list_punct,' '*len(list_punct))\n",
        "  new_review = ' '.join(review_text.translate(delete_punct).split())\n",
        "  return new_review\n",
        "text['content'] = text['content'].apply(lambda punct: remove_punctuation(punct))"
      ],
      "metadata": {
        "id": "ZoyfFMeAZKpv",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:37.689952Z",
          "iopub.execute_input": "2025-01-10T09:33:37.690247Z",
          "iopub.status.idle": "2025-01-10T09:33:37.732995Z",
          "shell.execute_reply.started": "2025-01-10T09:33:37.690219Z",
          "shell.execute_reply": "2025-01-10T09:33:37.732235Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_non_clear_symbol(word):\n",
        "    pattern = r'[^\\w\\s]'\n",
        "    cleaned_word = re.sub(pattern, '', word)\n",
        "    return cleaned_word\n",
        "text['content'] = text['content'].apply(lambda word: remove_non_clear_symbol(word))"
      ],
      "metadata": {
        "id": "6Ez6iIE4ZewE",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:37.733874Z",
          "iopub.execute_input": "2025-01-10T09:33:37.734146Z",
          "iopub.status.idle": "2025-01-10T09:33:37.752416Z",
          "shell.execute_reply.started": "2025-01-10T09:33:37.734119Z",
          "shell.execute_reply": "2025-01-10T09:33:37.751785Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def word_repetition(review_text):\n",
        "  review = re.sub(r'(.)\\1+', r'\\1\\1', review_text)\n",
        "  return review\n",
        "text['content'] = text['content'].apply(lambda word: word_repetition(word))\n",
        "\n",
        "def repetition(review_text):\n",
        "  repeat = re.sub(r'\\b(\\w+)(?:\\W\\1\\b)+', r'\\1',review_text, flags=re.IGNORECASE)\n",
        "  return repeat\n",
        "text['content'] = text['content'].apply(lambda word: repetition(word))"
      ],
      "metadata": {
        "id": "ZEEnCJVpZjsr",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:37.756078Z",
          "iopub.execute_input": "2025-01-10T09:33:37.756315Z",
          "iopub.status.idle": "2025-01-10T09:33:37.902281Z",
          "shell.execute_reply.started": "2025-01-10T09:33:37.756287Z",
          "shell.execute_reply": "2025-01-10T09:33:37.901400Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "bannedword = ['wkwk', 'wkwkw','wkwkwk','hihi','hihihii','hihihi','hehehe','hehehehe','hehe',\n",
        "              'huhu','huhuu','woy', 'tolol', 'anjing', 'babii','babi','terimakasih','anjir',\n",
        "              'the','najis','kocak','jancuk','amin','aduh','dongo','hehe','aamiin'\n",
        "              'ikhlas','kocak','lawak','hehe','lah','nya','woi','haha','hahaha','indodana','atome','kredivo',\n",
        "              'kreivo','kredivoo','akulaku','aplikasi','alhamdulillah', 'shopee', 'allobank', 'allo', 'ovo','gopay','paylater','pay','later','mybca','home','credit']\n",
        "re_banned_words = re.compile(r\"\\b(\" + \"|\".join(bannedword) + \")\\W\", re.I)\n",
        "\n",
        "def remove_banned_word(toPrint):\n",
        "    global re_banned_words\n",
        "    return re_banned_words.sub(\"\", toPrint)\n",
        "text['content'] = text['content'].apply(lambda banned:remove_banned_word(banned))"
      ],
      "metadata": {
        "id": "SGq725SvZpFl",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:37.903903Z",
          "iopub.execute_input": "2025-01-10T09:33:37.904218Z",
          "iopub.status.idle": "2025-01-10T09:33:38.111739Z",
          "shell.execute_reply.started": "2025-01-10T09:33:37.904188Z",
          "shell.execute_reply": "2025-01-10T09:33:38.111054Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "text.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:38.112591Z",
          "iopub.execute_input": "2025-01-10T09:33:38.112843Z",
          "iopub.status.idle": "2025-01-10T09:33:38.122352Z",
          "shell.execute_reply.started": "2025-01-10T09:33:38.112822Z",
          "shell.execute_reply": "2025-01-10T09:33:38.121731Z"
        },
        "id": "2o9EesenpvXy",
        "outputId": "e7ae74c5-63a0-4b13-a543-1e372c16a67d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4784 entries, 0 to 4783\nData columns (total 4 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   content        4784 non-null   object\n 1   score          4784 non-null   int64 \n 2   at             4784 non-null   object\n 3   platform_type  4784 non-null   object\ndtypes: int64(1), object(3)\nmemory usage: 149.6+ KB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "text.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:38.136634Z",
          "iopub.execute_input": "2025-01-10T09:33:38.136886Z",
          "iopub.status.idle": "2025-01-10T09:33:38.154890Z",
          "shell.execute_reply.started": "2025-01-10T09:33:38.136866Z",
          "shell.execute_reply": "2025-01-10T09:33:38.154161Z"
        },
        "id": "QPOo0rzmpvXy",
        "outputId": "7eb798a8-2e3b-4155-f9da-ee6d4dcd5ffe"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4784 entries, 0 to 4783\nData columns (total 4 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   content        4784 non-null   object\n 1   score          4784 non-null   int64 \n 2   at             4784 non-null   object\n 3   platform_type  4784 non-null   object\ndtypes: int64(1), object(3)\nmemory usage: 149.6+ KB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "text.isnull().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:38.155619Z",
          "iopub.execute_input": "2025-01-10T09:33:38.155871Z",
          "iopub.status.idle": "2025-01-10T09:33:38.173269Z",
          "shell.execute_reply.started": "2025-01-10T09:33:38.155852Z",
          "shell.execute_reply": "2025-01-10T09:33:38.172451Z"
        },
        "id": "qALCUM-PpvXz",
        "outputId": "14ccd3ff-6599-4284-c417-0811c95edfdb"
      },
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "content          0\nscore            0\nat               0\nplatform_type    0\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_extra_whitespaces(review_text):\n",
        "  review = re.sub(r'\\s+',' ', review_text)\n",
        "  return review\n",
        "text['content'] = text['content'].apply(lambda extra_spaces: remove_extra_whitespaces(extra_spaces))"
      ],
      "metadata": {
        "id": "Tl9gUeB8ZbIE",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:38.174244Z",
          "iopub.execute_input": "2025-01-10T09:33:38.174543Z",
          "iopub.status.idle": "2025-01-10T09:33:38.237523Z",
          "shell.execute_reply.started": "2025-01-10T09:33:38.174515Z",
          "shell.execute_reply": "2025-01-10T09:33:38.236864Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Data Preprocessing**"
      ],
      "metadata": {
        "id": "YkZbJdyVqaAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "slangs = open('slang.txt',\"r\",encoding=\"utf-8\", errors='replace')\n",
        "clear_slangs= []\n",
        "for newlines in slangs:\n",
        "  strip_re = newlines.strip(\"\\n\")\n",
        "  split = re.split(r'[:]',strip_re)\n",
        "  clear_slangs.append(split)\n",
        "slangs = [[k.strip(), v.strip()] for k,v in clear_slangs]\n",
        "dict_slangs = {key:values for key,values in slangs}\n",
        "\n",
        "clean_text = []\n",
        "for review in text['content']:\n",
        "  wordlist = TextBlob(review).words\n",
        "  for k,v in enumerate(wordlist):\n",
        "    if v in dict_slangs.keys():\n",
        "      wordlist[k] = dict_slangs[v]\n",
        "  clean_text.append(' '.join(wordlist))\n",
        "\n",
        "text['content'] = clean_text"
      ],
      "metadata": {
        "id": "TgsqfotCWj-_",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:38.238237Z",
          "iopub.execute_input": "2025-01-10T09:33:38.238530Z",
          "iopub.status.idle": "2025-01-10T09:33:39.240144Z",
          "shell.execute_reply.started": "2025-01-10T09:33:38.238502Z",
          "shell.execute_reply": "2025-01-10T09:33:39.239133Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def word_token(review_text):\n",
        "  return word_tokenize(review_text)\n",
        "text['token'] = text['content'].apply(lambda tokenize:word_token(str(tokenize)))"
      ],
      "metadata": {
        "id": "J_GEi-s-bcBT",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:39.241100Z",
          "iopub.execute_input": "2025-01-10T09:33:39.241351Z",
          "iopub.status.idle": "2025-01-10T09:33:39.923322Z",
          "shell.execute_reply.started": "2025-01-10T09:33:39.241331Z",
          "shell.execute_reply": "2025-01-10T09:33:39.922443Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('popular')\n",
        "indonesian_stop = stopwords.words('indonesian')\n",
        "stopwords_to_remove = ['tidak']\n",
        "modified_stopwords = [word for word in indonesian_stop if word not in stopwords_to_remove]\n",
        "\n",
        "stopwords_indo = pd.DataFrame(indonesian_stop, columns=['stopwords_indonenesia'])\n",
        "stopwords_indo.to_excel('stopwords_indonesian.xlsx', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLptIo3PbhYU",
        "outputId": "5a51c1de-1ecd-434b-bcb4-758fc0156ba6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:39.924108Z",
          "iopub.execute_input": "2025-01-10T09:33:39.924340Z",
          "iopub.status.idle": "2025-01-10T09:33:41.097070Z",
          "shell.execute_reply.started": "2025-01-10T09:33:39.924321Z",
          "shell.execute_reply": "2025-01-10T09:33:41.096431Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading collection 'popular'\n[nltk_data]    | \n[nltk_data]    | Downloading package cmudict to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package cmudict is already up-to-date!\n[nltk_data]    | Downloading package gazetteers to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package gazetteers is already up-to-date!\n[nltk_data]    | Downloading package genesis to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package genesis is already up-to-date!\n[nltk_data]    | Downloading package gutenberg to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package gutenberg is already up-to-date!\n[nltk_data]    | Downloading package inaugural to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package inaugural is already up-to-date!\n[nltk_data]    | Downloading package movie_reviews to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package movie_reviews is already up-to-date!\n[nltk_data]    | Downloading package names to /usr/share/nltk_data...\n[nltk_data]    |   Package names is already up-to-date!\n[nltk_data]    | Downloading package shakespeare to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package shakespeare is already up-to-date!\n[nltk_data]    | Downloading package stopwords to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package stopwords is already up-to-date!\n[nltk_data]    | Downloading package treebank to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package treebank is already up-to-date!\n[nltk_data]    | Downloading package twitter_samples to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package twitter_samples is already up-to-date!\n[nltk_data]    | Downloading package omw to /usr/share/nltk_data...\n[nltk_data]    |   Package omw is already up-to-date!\n[nltk_data]    | Downloading package omw-1.4 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package wordnet to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package wordnet is already up-to-date!\n[nltk_data]    | Downloading package wordnet2021 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package wordnet31 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package wordnet_ic to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package wordnet_ic is already up-to-date!\n[nltk_data]    | Downloading package words to /usr/share/nltk_data...\n[nltk_data]    |   Package words is already up-to-date!\n[nltk_data]    | Downloading package maxent_ne_chunker to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n[nltk_data]    | Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]    |   Package punkt is already up-to-date!\n[nltk_data]    | Downloading package snowball_data to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package snowball_data is already up-to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | \n[nltk_data]  Done downloading collection popular\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(review_text, modified_stopwords):\n",
        "  tokenize = []\n",
        "  for token in review_text:\n",
        "    if token not in modified_stopwords:\n",
        "      tokenize.append(token)\n",
        "  return tokenize\n",
        "\n",
        "text['token'] = text['token'].apply(lambda stop: remove_stopwords(stop, indonesian_stop))"
      ],
      "metadata": {
        "id": "fyR2ur5FbvIE",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:41.097790Z",
          "iopub.execute_input": "2025-01-10T09:33:41.098095Z",
          "iopub.status.idle": "2025-01-10T09:33:42.101454Z",
          "shell.execute_reply.started": "2025-01-10T09:33:41.098077Z",
          "shell.execute_reply": "2025-01-10T09:33:42.100540Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_text(review_text):\n",
        "    stop_token = ' '.join(review_text)\n",
        "    result_lemma = lemmatizer.lemmatize(stop_token)\n",
        "    return result_lemma\n",
        "\n",
        "text['lemmatized'] =text['token'].apply(lambda stem: lemmatize_text(stem))"
      ],
      "metadata": {
        "id": "b6qMMuBRcGxI",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:42.102290Z",
          "iopub.execute_input": "2025-01-10T09:33:42.102550Z",
          "iopub.status.idle": "2025-01-10T09:33:42.252520Z",
          "shell.execute_reply.started": "2025-01-10T09:33:42.102530Z",
          "shell.execute_reply": "2025-01-10T09:33:42.251873Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "text.info()\n",
        "text.tail()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:42.253227Z",
          "iopub.execute_input": "2025-01-10T09:33:42.253471Z",
          "iopub.status.idle": "2025-01-10T09:33:42.271676Z",
          "shell.execute_reply.started": "2025-01-10T09:33:42.253452Z",
          "shell.execute_reply": "2025-01-10T09:33:42.270951Z"
        },
        "id": "TBrfQFbKpvX2",
        "outputId": "beacb341-0471-4cf2-9003-504eef84240c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4784 entries, 0 to 4783\nData columns (total 6 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   content        4784 non-null   object\n 1   score          4784 non-null   int64 \n 2   at             4784 non-null   object\n 3   platform_type  4784 non-null   object\n 4   token          4784 non-null   object\n 5   lemmatized     4784 non-null   object\ndtypes: int64(1), object(5)\nmemory usage: 224.4+ KB\n",
          "output_type": "stream"
        },
        {
          "execution_count": 36,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                      content  score                   at platform_type  \\\n4779  lumayan sangat membantu      5  2023-08-03 10:59:59          lend   \n4780                      jos      5  2022-07-21 09:04:50          lend   \n4781         pengajuan credit      5  2021-10-28 15:55:01          lend   \n4782                 paylater      5  2021-05-20 22:28:05          lend   \n4783               tidak bisa      5  2024-06-15 14:59:02          lend   \n\n                    token     lemmatized  \n4779  [lumayan, membantu]  lumayan bantu  \n4780                [jos]            jos  \n4781  [pengajuan, credit]     aju credit  \n4782           [paylater]       paylater  \n4783                   []                 ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>score</th>\n      <th>at</th>\n      <th>platform_type</th>\n      <th>token</th>\n      <th>lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4779</th>\n      <td>lumayan sangat membantu</td>\n      <td>5</td>\n      <td>2023-08-03 10:59:59</td>\n      <td>lend</td>\n      <td>[lumayan, membantu]</td>\n      <td>lumayan bantu</td>\n    </tr>\n    <tr>\n      <th>4780</th>\n      <td>jos</td>\n      <td>5</td>\n      <td>2022-07-21 09:04:50</td>\n      <td>lend</td>\n      <td>[jos]</td>\n      <td>jos</td>\n    </tr>\n    <tr>\n      <th>4781</th>\n      <td>pengajuan credit</td>\n      <td>5</td>\n      <td>2021-10-28 15:55:01</td>\n      <td>lend</td>\n      <td>[pengajuan, credit]</td>\n      <td>aju credit</td>\n    </tr>\n    <tr>\n      <th>4782</th>\n      <td>paylater</td>\n      <td>5</td>\n      <td>2021-05-20 22:28:05</td>\n      <td>lend</td>\n      <td>[paylater]</td>\n      <td>paylater</td>\n    </tr>\n    <tr>\n      <th>4783</th>\n      <td>tidak bisa</td>\n      <td>5</td>\n      <td>2024-06-15 14:59:02</td>\n      <td>lend</td>\n      <td>[]</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def join_text(review_text):\n",
        "    stop_token = ' '.join(review_text)\n",
        "    return stop_token\n",
        "text['clean'] = text['token'] .apply(lambda tokens: join_text(tokens))"
      ],
      "metadata": {
        "id": "ksCiapA7dS8R",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:42.272532Z",
          "iopub.execute_input": "2025-01-10T09:33:42.272743Z",
          "iopub.status.idle": "2025-01-10T09:33:42.290999Z",
          "shell.execute_reply.started": "2025-01-10T09:33:42.272726Z",
          "shell.execute_reply": "2025-01-10T09:33:42.290127Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def count_words(sentence):\n",
        "    return len(sentence.split())\n",
        "text = text[text['clean'].apply(count_words) >= 3]"
      ],
      "metadata": {
        "id": "5tKHEUMujRoj",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:42.292039Z",
          "iopub.execute_input": "2025-01-10T09:33:42.292275Z",
          "iopub.status.idle": "2025-01-10T09:33:42.313427Z",
          "shell.execute_reply.started": "2025-01-10T09:33:42.292256Z",
          "shell.execute_reply": "2025-01-10T09:33:42.312580Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "text['at'] = pd.to_datetime(text['at'])\n",
        "text['period'] = text['at'].dt.to_period('M')"
      ],
      "metadata": {
        "id": "3mrICcH86D7W",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:42.314166Z",
          "iopub.execute_input": "2025-01-10T09:33:42.314494Z",
          "iopub.status.idle": "2025-01-10T09:33:42.337256Z",
          "shell.execute_reply.started": "2025-01-10T09:33:42.314472Z",
          "shell.execute_reply": "2025-01-10T09:33:42.336444Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "text.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T09:33:42.338091Z",
          "iopub.execute_input": "2025-01-10T09:33:42.338414Z",
          "iopub.status.idle": "2025-01-10T09:33:42.359073Z",
          "shell.execute_reply.started": "2025-01-10T09:33:42.338382Z",
          "shell.execute_reply": "2025-01-10T09:33:42.358291Z"
        },
        "id": "odNA3Eg7pvYB",
        "outputId": "68735acd-910a-4d0d-fcf9-1a759c2aa5c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nIndex: 4488 entries, 0 to 4778\nData columns (total 8 columns):\n #   Column         Non-Null Count  Dtype         \n---  ------         --------------  -----         \n 0   content        4488 non-null   object        \n 1   score          4488 non-null   int64         \n 2   at             4488 non-null   datetime64[ns]\n 3   platform_type  4488 non-null   object        \n 4   token          4488 non-null   object        \n 5   lemmatized     4488 non-null   object        \n 6   clean          4488 non-null   object        \n 7   period         4488 non-null   period[M]     \ndtypes: datetime64[ns](1), int64(1), object(5), period[M](1)\nmemory usage: 315.6+ KB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}